{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "828a2450",
   "metadata": {},
   "source": [
    "\n",
    "# Trader Behavior Insights â€” Junior Data Scientist Assignment\n",
    "\n",
    "**Candidate:** K. Rajasekhar\n",
    "\n",
    "**Objective:** Analyze relationship between trader performance (Hyperliquid trades) and Bitcoin market sentiment (Fear/Greed index). This Colab notebook contains data loading, cleaning, aggregation, merging with sentiment, EDA, visualizations, and key insights.\n",
    "\n",
    "**Files provided:** `historical_data.csv`, `fear_greed_index.csv` (placed in `/content` when running in Colab) or use Google Drive links.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004fa6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Setup - imports and helper functions\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# Paths (adjust if using Colab with Drive)\n",
    "DATA_DIR = Path('/content')  # replace with your drive mount path if needed\n",
    "HIST = DATA_DIR/'historical_data.csv'\n",
    "FG = DATA_DIR/'fear_greed_index.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553a6544",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load small samples to inspect\n",
    "hist = pd.read_csv(HIST, low_memory=False, nrows=1000)\n",
    "fg = pd.read_csv(FG, low_memory=False, nrows=1000)\n",
    "print('Historical sample columns:', hist.columns.tolist())\n",
    "print('Fear-Greed columns:', fg.columns.tolist())\n",
    "hist.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47639c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Full processing (chunked) - produces daily_aggregates.csv and merged_daily_sentiment.csv\n",
    "def process_historical(infile, out_daily='daily_aggregates.csv', chunksize=150000):\n",
    "    cols = None\n",
    "    agg_frames = []\n",
    "    for chunk in pd.read_csv(infile, chunksize=chunksize, low_memory=False):\n",
    "        # normalize columns\n",
    "        chunk.columns = [c.strip() for c in chunk.columns]\n",
    "        # detect time column\n",
    "        time_col = None\n",
    "        for c in chunk.columns:\n",
    "            if 'time' in c.lower():\n",
    "                time_col = c\n",
    "                break\n",
    "        if time_col is None:\n",
    "            raise ValueError('No time column found in historical data.')\n",
    "        chunk[time_col] = pd.to_datetime(chunk[time_col], errors='coerce')\n",
    "        chunk['date'] = chunk[time_col].dt.date\n",
    "        # numeric conversions\n",
    "        for col in ['Closed PnL','Closed PnL ','ClosedPnL','closed_pnl','closed pnl','Closed PnL USD']:\n",
    "            if col in chunk.columns:\n",
    "                chunk['closed_pnl'] = pd.to_numeric(chunk[col].astype(str).str.replace(',',''), errors='coerce')\n",
    "                break\n",
    "        for col in ['Size USD','Size_USD','size_usd','size usd']:\n",
    "            if col in chunk.columns:\n",
    "                chunk['size_usd'] = pd.to_numeric(chunk[col].astype(str).str.replace(',',''), errors='coerce')\n",
    "                break\n",
    "        for col in ['Fee','fee']:\n",
    "            if col in chunk.columns:\n",
    "                chunk['fee'] = pd.to_numeric(chunk[col].astype(str).str.replace(',',''), errors='coerce')\n",
    "                break\n",
    "        daily = chunk.groupby('date').agg(\n",
    "            trades_count = ('closed_pnl','count'),\n",
    "            pnl_sum = ('closed_pnl','sum'),\n",
    "            pnl_mean = ('closed_pnl','mean'),\n",
    "            pnl_median = ('closed_pnl','median'),\n",
    "            win_count = ('closed_pnl', lambda s: (s>0).sum()),\n",
    "            avg_size_usd = ('size_usd','mean') if 'size_usd' in chunk.columns else ('closed_pnl','mean'),\n",
    "            avg_fee = ('fee','mean') if 'fee' in chunk.columns else ('closed_pnl','mean')\n",
    "        ).reset_index()\n",
    "        agg_frames.append(daily)\n",
    "    agg_all = pd.concat(agg_frames, ignore_index=True)\n",
    "    agg_final = agg_all.groupby('date').agg(\n",
    "        trades_count = ('trades_count','sum'),\n",
    "        pnl_sum = ('pnl_sum','sum'),\n",
    "        pnl_mean = ('pnl_mean','mean'),\n",
    "        pnl_median = ('pnl_median','mean'),\n",
    "        win_count = ('win_count','sum'),\n",
    "        avg_size_usd = ('avg_size_usd','mean'),\n",
    "        avg_fee = ('avg_fee','mean')\n",
    "    ).reset_index()\n",
    "    agg_final['win_rate'] = agg_final['win_count'] / agg_final['trades_count']\n",
    "    agg_final.to_csv(out_daily, index=False)\n",
    "    return agg_final\n",
    "\n",
    "def merge_with_sentiment(daily_csv, fg_csv, out_merged='merged_daily_sentiment.csv'):\n",
    "    df_daily = pd.read_csv(daily_csv, parse_dates=['date'])\n",
    "    fg = pd.read_csv(fg_csv, parse_dates=['date'])\n",
    "    df_daily['date'] = pd.to_datetime(df_daily['date']).dt.date\n",
    "    fg['date'] = pd.to_datetime(fg['date']).dt.date\n",
    "    merged = pd.merge(df_daily, fg[['date','classification']], on='date', how='left')\n",
    "    merged.to_csv(out_merged, index=False)\n",
    "    return merged\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c8b29c",
   "metadata": {},
   "source": [
    "\n",
    "## Suggested Analyses\n",
    "\n",
    "- Compare **avg daily PnL** and **win rate** between `Fear` vs `Greed` days.\n",
    "- Visualizations to include in `outputs/`:\n",
    "  - Boxplot of daily `pnl_sum` by `classification`\n",
    "  - Time series of `pnl_sum` with sentiment markers\n",
    "  - Scatter: avg_leverage vs pnl_sum (if leverage exists)\n",
    "  - Top symbols profitability by sentiment\n",
    "\n",
    "## Deliverables\n",
    "- `notebook_1.ipynb` (this notebook)\n",
    "- `csv_files/daily_aggregates.csv`\n",
    "- `csv_files/merged_daily_sentiment.csv`\n",
    "- `outputs/*.png`\n",
    "- `ds_report.pdf`\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
